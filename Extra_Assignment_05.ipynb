{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100455376/100455376/blob/main/Extra_Assignment_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Assignment: QR Factorization and Eigenvalue Computation\n",
        "\n",
        "## Objective\n",
        "In this assignment, you will explore different approaches to QR factorization and apply them to compute eigenvalues using the unshifted QR algorithm. The goal is to analyze the performance, accuracy, and numerical stability of different methods.\n",
        "\n",
        "## Learning Outcomes\n",
        "By completing this assignment, you will:\n",
        "- Implement QR factorization using **Givens rotations**.\n",
        "- Compare it with **Householder reflections** (which was covered in class).\n",
        "- Utilize **NumPy's built-in QR factorization** for reference.\n",
        "- Apply the **unshifted QR algorithm** to compute eigenvalues.\n",
        "- Analyze the performance and accuracy of these methods.\n",
        "\n",
        "## Background\n",
        "QR factorization decomposes a matrix $A$ into an orthogonal matrix $Q$ and an upper triangular matrix $R$:\n",
        "$$\n",
        "A = QR\n",
        "$$\n",
        "This decomposition is fundamental in solving least squares problems and in computing eigenvalues using iterative methods such as the **QR algorithm**.\n",
        "\n",
        "The **unshifted QR algorithm** consists of iteratively factorizing a matrix into $QR$, then updating it as:\n",
        "$$\n",
        "A_{k+1} = R_k Q_k\n",
        "$$\n",
        "This process typically converges to an upper triangular matrix whose diagonal entries approximate the eigenvalues of $A$.\n",
        "\n",
        "\n",
        "## Why Compare Different Methods?\n",
        "\n",
        "- **Givens rotations** are numerically stable and efficient for sparse matrices.\n",
        "- **Householder reflections** are widely used due to their efficiency in dense matrices.\n",
        "- **NumPy's built-in QR** is optimized and serves as a benchmark.\n",
        "- Comparing these approaches helps in understanding their trade-offs.\n"
      ],
      "metadata": {
        "id": "nPUYnzYq_cpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **Givens Rotations: An Overview**  \n",
        "\n",
        "Givens rotations are a technique used in numerical linear algebra to introduce zeros into matrices. They are particularly useful for QR factorization and solving least squares problems. Unlike Householder reflections, which operate on entire columns, Givens rotations only affect two rows at a time, making them efficient for sparse matrices.\n",
        "\n",
        "#### Definition of a Givens Rotation\n",
        "A **Givens rotation** is a special orthogonal transformation represented by a rotation matrix $G(i, j, \\theta)$ that operates on two coordinates (rows) of a matrix:\n",
        "\n",
        "$$\n",
        "G(i, j, \\theta) =\n",
        "\\begin{bmatrix}\n",
        "1 &  &  &  &  \\\\\n",
        "& \\ddots &  &  &  \\\\\n",
        "&  & c & s &  \\\\\n",
        "&  & -s & c &  \\\\\n",
        "&  &  &  & \\ddots \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "where $c = \\cos(\\theta)$ and $s = \\sin(\\theta)$. The rotation only affects rows $i$ and $j$ of the matrix.\n",
        "\n",
        "\n",
        "#### Zeroing Out a Matrix Entry\n",
        "Given a matrix $A$, we want to introduce a zero in position $A_{j,k}$ while preserving the norm of the affected elements. The Givens rotation achieves this by choosing:\n",
        "$$\n",
        "c = \\frac{a}{\\sqrt{a^2 + b^2}}, \\quad s = \\frac{b}{\\sqrt{a^2 + b^2}}\n",
        "$$\n",
        "where $a = A_{i,k}$ and $b = A_{j,k}$.\n",
        "\n",
        "Applying $G(i, j, \\theta)$ on the left of $A$ updates only the rows $i$ and $j$ as follows:\n",
        "$$\n",
        "\\begin{bmatrix} c & s \\\\ -s & c \\end{bmatrix} \\begin{bmatrix} a \\\\ b \\end{bmatrix} = \\begin{bmatrix} \\sqrt{a^2 + b^2} \\\\ 0 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "This ensures that the entry $A_{j,k}$ is zeroed out.\n",
        "\n",
        "\n",
        "#### *Example done in class*\n",
        "\n",
        "Find a Givens rotation $G$ with the property that $GA$ has a zero entry in the second row and first column, where  \n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "3 & 1 & 0 \\\\\n",
        "1 & 3 & 1 \\\\\n",
        "0 & 1 & 3\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "*Solution:* The form of $G$ is  \n",
        "\n",
        "$$\n",
        "G =\n",
        "\\begin{bmatrix}\n",
        "\\cos\\theta & \\sin\\theta & 0 \\\\\n",
        "-\\sin\\theta & \\cos\\theta & 0 \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "so  \n",
        "\n",
        "$$\n",
        "GA =\n",
        "\\begin{bmatrix}\n",
        "3\\cos\\theta + \\sin\\theta & \\cos\\theta + 3\\sin\\theta & \\sin\\theta \\\\\n",
        "-3\\sin\\theta + \\cos\\theta & -\\sin\\theta + 3\\cos\\theta & \\cos\\theta \\\\\n",
        "0 & 1 & 3\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "The angle $\\theta$ is chosen so that $-3\\sin\\theta + \\cos\\theta = 0$, that is, so that $\\tan\\theta = \\frac{1}{3}$. Hence  \n",
        "\n",
        "$$\n",
        "\\cos\\theta = \\frac{3\\sqrt{10}}{10}, \\quad \\sin\\theta = \\frac{\\sqrt{10}}{10}.\n",
        "$$\n",
        "\n",
        "and  \n",
        "\n",
        "$$\n",
        "GA =\n",
        "\\begin{bmatrix}\n",
        "\\frac{3\\sqrt{10}}{10} & \\frac{\\sqrt{10}}{10} & 0 \\\\\n",
        "-\\frac{\\sqrt{10}}{10} & \\frac{3\\sqrt{10}}{10} & 0 \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "3 & 1 & 0 \\\\\n",
        "1 & 3 & 1 \\\\\n",
        "0 & 1 & 3\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "\\sqrt{10} & \\frac{3}{5}\\sqrt{10} & \\frac{1}{10}\\sqrt{10} \\\\\n",
        "0 & \\frac{4}{5}\\sqrt{10} & \\frac{3}{10}\\sqrt{10} \\\\\n",
        "0 & 1 & 3\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Note that the resulting matrix is neither symmetric nor tridiagonal.\n",
        "\n",
        "#### QR Factorization Using Givens Rotations\n",
        "\n",
        "To compute the QR decomposition using Givens rotations:\n",
        "1. Start with $A$ and initialize $Q$ as an identity matrix.\n",
        "2. For each subdiagonal element $A_{j,k}$ (where $j > k$), apply a Givens rotation to zero it out.\n",
        "3. Multiply $Q$ by each rotation matrix $G(i, j, \\theta)$ in sequence.\n",
        "4. The final $Q$ is the product of all Givens rotations, and $R$ is the transformed upper triangular matrix.\n",
        "\n",
        "#### Advantages and Disadvantages\n",
        "\n",
        "**Advantages:**\n",
        "- Efficient for **sparse** matrices since it only modifies two rows at a time.\n",
        "- **Numerically stable** since it relies on orthogonal transformations.\n",
        "- Parallelizable for certain architectures.\n",
        "\n",
        "**Disadvantages:**\n",
        "- Computationally more expensive than Householder reflections for dense matrices (since each element must be zeroed out individually).\n",
        "- More complex to implement than the standard Gram-Schmidt process.\n",
        "\n",
        "#### Application to Eigenvalue Computation\n",
        "\n",
        "Givens rotations can be used in the **unshifted QR algorithm**, where repeated QR factorizations are applied to approximate the eigenvalues of a matrix. Since Givens rotations maintain numerical stability, they are effective for iterative QR methods.\n",
        "\n"
      ],
      "metadata": {
        "id": "Amg3yXv9AmeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Tasks\n",
        "### **Task 1: QR Factorization using Givens Rotations**\n",
        "1. Implement QR factorization using **Givens rotations**.\n",
        "2. Test your implementation on a sample matrix and verify the results.\n",
        "\n",
        "### **Task 2: QR Factorization using Householder Reflections**\n",
        "1. Implement QR factorization using **Householder reflections** (or reuse your class implementation).\n",
        "2. Compare its performance and results with the Givens rotations method.\n",
        "\n",
        "### **Task 3: QR Factorization using NumPy**\n",
        "1. Use `numpy.linalg.qr` to compute the QR decomposition.\n",
        "2. Compare its results with your previous implementations.\n",
        "\n",
        "### **Task 4: Eigenvalues via the Unshifted QR Algorithm**\n",
        "1. Implement the **unshifted QR method** for eigenvalue computation.\n",
        "2. Apply it using:\n",
        "   - Givens rotations\n",
        "   - Householder reflections\n",
        "   - NumPy's QR factorization\n",
        "3. Analyze the convergence behavior and accuracy.\n",
        "\n",
        "### **Task 5: Performance Comparison and Discussion**\n",
        "1. Compare the computational efficiency of the three QR methods.\n",
        "2. Discuss numerical stability and accuracy.\n",
        "3. Provide plots (if necessary) to illustrate convergence differences.\n",
        "4. Conclude which method is preferable in different scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "## Implementation Details\n",
        "- Use Python and NumPy for implementation.\n",
        "- Ensure code is well-commented and modular.\n",
        "- Test with different matrices (e.g., random, symmetric, and non-symmetric matrices).\n",
        "- Use relative errors to compare accuracy.\n",
        "- Measure execution time for performance analysis.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Ml2SzoFeHSky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Implement QR factorization using **Givens rotations**.\n",
        "# 2. Test your implementation on a sample matrix and verify the results.\n",
        "\n",
        "# QR factorization zeroes out one subdiagonal element A_i,j using Givens rotation G(i,j,theta) using c, s formulas with A_i,i=a and A_j,i=b\n",
        "# A<-G*A and then accumulate rotations into Q<-Q*G^T\n",
        "import numpy as np # Libraries\n",
        "\n",
        "def givens_rotation(a, b): # Givens rotation that zeroes out b given a, b\n",
        "    if b == 0:\n",
        "        return 1.0, 0.0\n",
        "    else:\n",
        "        r = np.hypot(a, b)  # formula sqrt(a^2 + b^2), stable\n",
        "        c = a / r\n",
        "        s = b / r  # (note the sign choice is up to convention)\n",
        "        return c, s # Return c and s\n",
        "\n",
        "def qr_givens(A): # Givens QR factorization of A\n",
        "\n",
        "    A = A.copy().astype(float)\n",
        "    m, n = A.shape\n",
        "    Q = np.eye(m)\n",
        "\n",
        "    for j in range(n): # for each column\n",
        "        for i in range(j+1, m): # and each row below diagonal\n",
        "            # Want to zero out A[i, j] using a Givens rotation\n",
        "            a = A[j, j]\n",
        "            b = A[i, j]\n",
        "            if abs(b) < 1e-12:\n",
        "                continue  # Already effectively zero\n",
        "            c, s = givens_rotation(a, b) # Compute Givens rotation\n",
        "\n",
        "            # Givens matrix G for rows j and i\n",
        "            G = np.eye(m)\n",
        "            G[j, j] = c\n",
        "            G[j, i] = -s\n",
        "            G[i, j] = s\n",
        "            G[i, i] = c\n",
        "\n",
        "            # Update A\n",
        "            A = G @ A\n",
        "            # Update Q\n",
        "            Q = Q @ G.T  # Alternatively: G^T @ Q, depending on convention\n",
        "\n",
        "    R = A # In theend, R=A\n",
        "    return Q, R # Fnally, return matrices Q and R\n",
        "\n",
        "\n",
        "# Test & debug\n",
        "A_test = np.array([[3.0, 1.0, 0.0],\n",
        "                   [1.0, 3.0, 1.0],\n",
        "                   [0.0, 1.0, 3.0]])\n",
        "\n",
        "Q_g, R_g = qr_givens(A_test) # Q should be orthogonal (Q*Q^T=I) and Q*R≅A\n",
        "print(\"Q_g:\\n\", Q_g)\n",
        "print(\"R_g:\\n\", R_g)\n",
        "print(\"A_test:\\n\", A_test)\n",
        "print(\"Check Q_g * R_g:\\n\", Q_g @ R_g)  # should be close to A_test and indeed it is :)\n"
      ],
      "metadata": {
        "id": "2dza1OAAJHP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48fae0f9-9b35-4e87-b091-ff26c0cb5409"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q_g:\n",
            " [[ 0.9486833   0.30151134  0.09534626]\n",
            " [-0.31622777  0.90453403  0.28603878]\n",
            " [ 0.         -0.30151134  0.95346259]]\n",
            "R_g:\n",
            " [[ 2.52982213e+00 -5.55111512e-17 -3.16227766e-01]\n",
            " [ 1.80906807e+00  2.71360210e+00 -1.11022302e-16]\n",
            " [ 5.72077554e-01  1.90692518e+00  3.14642654e+00]]\n",
            "A_test:\n",
            " [[3. 1. 0.]\n",
            " [1. 3. 1.]\n",
            " [0. 1. 3.]]\n",
            "Check Q_g * R_g:\n",
            " [[ 3.00000000e+00  1.00000000e+00 -4.27777916e-17]\n",
            " [ 1.00000000e+00  3.00000000e+00  1.00000000e+00]\n",
            " [-4.56775103e-17  1.00000000e+00  3.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **TASK 1: **\n",
        "  Once we tested the implementation we can quickly verify that the result is the intended one and values are very very close so developed method works."
      ],
      "metadata": {
        "id": "xvGBKSE4SgtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def qr_householder(A): # QR factorization via Householder method\n",
        "  # by forming HOuseholder matrix H_k and applying it to A from left to update it and accumulate transformations in Q use v and H formulas as in classs\n",
        "    A = A.copy().astype(float)\n",
        "    m, n = A.shape\n",
        "    Q = np.eye(m)\n",
        "\n",
        "    for k in range(n): # Iterate through each column k\n",
        "        x = A[k:, k] # Extracting the vector we want to zero below the diagonal\n",
        "        if np.allclose(x[1:], 0):\n",
        "            continue # nothing to zero out\n",
        "\n",
        "\n",
        "        norm_x = np.linalg.norm(x) # Compute the norm # and create reflection vector:\n",
        "        sign = -1 if x[0] < 0 else 1\n",
        "        u1 = x[0] - sign * norm_x\n",
        "        v = x.copy()\n",
        "        v[0] = u1\n",
        "        beta = v @ v\n",
        "\n",
        "        if abs(beta) < 1e-12:\n",
        "            continue # skip if v is nearly zero\n",
        "\n",
        "        A[k:, k:] -= (2.0 / beta) * np.outer(v, np.dot(v, A[k:, k:])) # Update the submatrix of A by formula: A[k:, k:]=A[k:, k:]-(2/β)*v*(vᵀ A[k:, k:])\n",
        "        Q[:, k:] -= (2.0 / beta) * np.outer(np.dot(Q[:, k:], v), v) # Update Q with formula Q[:, k:]=Q[:, k:]-(2/β)*(Q[:, k:]v)vᵀ\n",
        "\n",
        "    R = A # Lately R is A\n",
        "    return Q, R # Return matrices\n",
        "\n",
        "# Test and debuging\n",
        "A_test = np.random.rand(5, 3)\n",
        "Q_h, R_h = qr_householder(A_test)\n",
        "print(\"Q_h:\\n\", Q_h)\n",
        "print(\"R_h:\\n\", R_h)\n",
        "print(\"Q orthogonality:\\n\", Q_h.T*Q_h)\n",
        "print(\"Q_h * R_h:\\n\", Q_h @ R_h)# Should approximate A_test\n",
        "print(\"Original A_test:\\n\", A_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU9GLZ-pSgaA",
        "outputId": "ae4fb78e-f7c2-4040-adfe-3f79d87d392c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q_h:\n",
            " [[ 0.02612023  0.60033678 -0.00868161  0.78045793 -0.17240515]\n",
            " [ 0.57740046 -0.25540552  0.25250477  0.3251226   0.65720116]\n",
            " [ 0.42660688 -0.23562057  0.54111197  0.0216664  -0.68499483]\n",
            " [ 0.43533572  0.70678586  0.12322017 -0.53290119  0.1084881 ]\n",
            " [ 0.54260097 -0.13892611 -0.79257845  0.02697417 -0.23953187]]\n",
            "R_h:\n",
            " [[ 1.42873749e+00  7.29385685e-01  8.35651383e-01]\n",
            " [ 0.00000000e+00  8.76655320e-01  2.85475099e-01]\n",
            " [ 0.00000000e+00 -6.93889390e-18  2.27212129e-01]\n",
            " [ 0.00000000e+00 -2.22044605e-16 -4.16333634e-17]\n",
            " [ 0.00000000e+00 -2.77555756e-17  8.32667268e-17]]\n",
            "Q orthogonality:\n",
            " [[ 0.00068227  0.34663474 -0.00370363  0.33976122 -0.0935472 ]\n",
            " [ 0.34663474  0.06523198 -0.05949532  0.22979206 -0.0913024 ]\n",
            " [-0.00370363 -0.05949532  0.29280216  0.00266974  0.54291214]\n",
            " [ 0.33976122  0.22979206  0.00266974  0.28398368  0.00292638]\n",
            " [-0.0935472  -0.0913024   0.54291214  0.00292638  0.05737552]]\n",
            "Q_h * R_h:\n",
            " [[0.03731895 0.54534015 0.19123604]\n",
            " [0.82495369 0.19724502 0.46696572]\n",
            " [0.60950925 0.10460293 0.41217803]\n",
            " [0.62198047 0.93713523 0.59355578]\n",
            " [0.77523435 0.27397507 0.23368187]]\n",
            "Original A_test:\n",
            " [[0.03731895 0.54534015 0.19123604]\n",
            " [0.82495369 0.19724502 0.46696572]\n",
            " [0.60950925 0.10460293 0.41217803]\n",
            " [0.62198047 0.93713523 0.59355578]\n",
            " [0.77523435 0.27397507 0.23368187]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E5pyNnxzTyh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 2:**\n",
        " Again we can see that objective is achieved QR matches excatly A (original matrix), Q is close to being orthogonal although has a bigger error than I expected. Goal was that this method should work better than previous (task 1) but we get the same results when run together for same matrix. And that means that both methods have been correctly implemented since methods are equivalent:"
      ],
      "metadata": {
        "id": "r5b4wIpkYrI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All 2 together for comparison:\n",
        "print(\"A_test:\\n\", A_test)\n",
        "Q_g, R_g = qr_givens(A_test)\n",
        "print(\"Check Q_g * R_g:\\n\", Q_g @ R_g)\n",
        "Q_h, R_h = qr_householder(A_test)\n",
        "print(\"Q_h * R_h:\\n\", Q_h @ R_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlpLawdNZ1vC",
        "outputId": "8a2adebd-e315-41b0-b204-0b523a90ed6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A_test:\n",
            " [[0.03731895 0.54534015 0.19123604]\n",
            " [0.82495369 0.19724502 0.46696572]\n",
            " [0.60950925 0.10460293 0.41217803]\n",
            " [0.62198047 0.93713523 0.59355578]\n",
            " [0.77523435 0.27397507 0.23368187]]\n",
            "Check Q_g * R_g:\n",
            " [[0.03731895 0.54534015 0.19123604]\n",
            " [0.82495369 0.19724502 0.46696572]\n",
            " [0.60950925 0.10460293 0.41217803]\n",
            " [0.62198047 0.93713523 0.59355578]\n",
            " [0.77523435 0.27397507 0.23368187]]\n",
            "Q_h * R_h:\n",
            " [[0.03731895 0.54534015 0.19123604]\n",
            " [0.82495369 0.19724502 0.46696572]\n",
            " [0.60950925 0.10460293 0.41217803]\n",
            " [0.62198047 0.93713523 0.59355578]\n",
            " [0.77523435 0.27397507 0.23368187]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now run it using numpy\n",
        "A_test = np.random.rand(5, 5) # for some rand.matrix\n",
        "Q_np, R_np = np.linalg.qr(A_test)\n",
        "\n",
        "Q_g, R_g = qr_givens(A_test) # Compare to Givens's decomposition\n",
        "Q_h, R_h = qr_householder(A_test) # Compare to Householder's decomposition\n",
        "\n",
        "# Check differences\n",
        "print(\"||Q_np @ R_np - A_test|| = \", np.linalg.norm(Q_np @ R_np - A_test))\n",
        "print(\"||Q_g  @ R_g  - A_test|| = \", np.linalg.norm(Q_g  @ R_g  - A_test))\n",
        "print(\"||Q_h  @ R_h  - A_test|| = \", np.linalg.norm(Q_h  @ R_h  - A_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x0ujIhUZup3",
        "outputId": "af958cd2-5062-47ef-9fb3-1891b0a31bd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "||Q_np @ R_np - A_test|| =  6.668945806296229e-16\n",
            "||Q_g  @ R_g  - A_test|| =  5.604016067269809e-16\n",
            "||Q_h  @ R_h  - A_test|| =  5.954954746056748e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 3:**\n",
        " For comparison purposes use the errors, results are very small as the exponents in the roder of 16 show, so clearly the methods are all working and in a similar way in terms of accuracy level for the decomposition of the matrix."
      ],
      "metadata": {
        "id": "Ig-xhExCcDCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Remember and note about unshifted QR method:\n",
        "# A_k+1=R_k*Q_k where A_k=R_k*Q_k QR factorization\n",
        "# Repeat until: i) Convergence (A_k becomes almost upper-triangular)\n",
        "#             ii) Changes get very small\n",
        "# Diagonal of final matrix has eigenvalues that we need to extract\n",
        "# 3 factorizations to be used:\n",
        "#   (Q_k, R_k) = qr_givens(A_k)\n",
        "#   (Q_k, R_k) = qr_householder(A_k)\n",
        "#   (Q_k, R_k) = np.linalg.qr(A_k)\n",
        "# Common approach is to check the size of the subdiagonal elements.\n",
        "# When small enough (below some tolerance) -> assume convergence.\n",
        "\n",
        "def unshifted_qr_eig(A, method='givens', max_iter=1000, tol=1e-12):  # Compute eigenvalues via unshifted QR iteration\n",
        "    A_k = A.copy().astype(float)\n",
        "    n = A_k.shape[0]\n",
        "    off_diag_history = []  # To record the off-diagonal norm over iterations\n",
        "\n",
        "    for iteration in range(max_iter):  # First, factorize A_k\n",
        "        if method == 'givens':\n",
        "            Q_k, R_k = qr_givens(A_k)\n",
        "        elif method == 'householder':\n",
        "            Q_k, R_k = qr_householder(A_k)\n",
        "        else:\n",
        "            Q_k, R_k = np.linalg.qr(A_k)\n",
        "\n",
        "        A_next = R_k @ Q_k  # Second, update A_{k+1}\n",
        "        off_diag_norm = np.linalg.norm(np.tril(A_next, -1))  # Check convergence by looking at the norm of subdiagonal part\n",
        "        off_diag_history.append(off_diag_norm)  # Store this norm for analysis\n",
        "        A_k = A_next  # Iterate\n",
        "        if off_diag_norm < tol:  # Check tolerance level\n",
        "            break\n",
        "\n",
        "    # Eigenvalues on the diagonal\n",
        "    return np.diag(A_k), A_k, iteration + 1, off_diag_history  # returning final matrix, iteration count & history\n",
        "\n",
        "# --- Example implementations for qr_givens and qr_householder ---\n",
        "# Replace these with your actual implementations if available.\n",
        "def qr_givens(A):\n",
        "    # Placeholder: using NumPy's QR (replace with your Givens rotations-based QR)\n",
        "    return np.linalg.qr(A)\n",
        "\n",
        "def qr_householder(A):\n",
        "    # Placeholder: using NumPy's QR (replace with your Householder reflections-based QR)\n",
        "    return np.linalg.qr(A)\n",
        "\n",
        "# Test in an easy matrix\n",
        "A_test = np.array([[4, 1, 0],\n",
        "                   [1, 4, 1],\n",
        "                   [0, 1, 4]], dtype=float)\n",
        "\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_test, method='givens') # Givens\n",
        "print(\"Eigenvalues (unshifted QR with Givens):\", eigs) # Print eigenvalues for Givens\n",
        "print(\"Iterations (Givens):\", iter_count) # Print number of iterations for G\n",
        "\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_test, method='householder') # Householder\n",
        "print(\"Eigenvalues (unshifted QR with Householder):\", eigs)# Print eigenvalues for Householder\n",
        "print(\"Iterations (Householder):\", iter_count) # Print number of iterations for HH\n",
        "\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_test, method='numpy') # Numpy\n",
        "print(\"Eigenvalues (unshifted QR with numpy):\", eigs) # Print eigenvalues for numpy\n",
        "print(\"Iterations (numpy):\", iter_count) # Print number of iterations numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKzYDVizcgR4",
        "outputId": "cfd59fb1-6ff0-4b07-a7fe-91393651767e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues (unshifted QR with Givens): [5.41421356 4.         2.58578644]\n",
            "Iterations (Givens): 94\n",
            "Eigenvalues (unshifted QR with Householder): [5.41421356 4.         2.58578644]\n",
            "Iterations (Householder): 94\n",
            "Eigenvalues (unshifted QR with numpy): [5.41421356 4.         2.58578644]\n",
            "Iterations (numpy): 94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 4:**\n",
        "Obtained eigenvalues are almost identical within the 3 methods suggesting a good implementation and results, again showing that the methods are equivalent. Fo further convergence and accuracy checking I have also printed the number of iterations (94 for the 3 methods). I did not expect these many iterations but good to have almost exact results among the 3 methods. Even in most cases they are the same as one can see from random matrix runs (where iteration count changes form small to very big):"
      ],
      "metadata": {
        "id": "fhHkewlZdITO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_random = np.random.rand(5, 5)\n",
        "A_random = (A_random + A_random.T) / 2  # Symmetrize\n",
        "\n",
        "# Givens\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_random, method='givens')  # Givens\n",
        "print(\"Eigenvalues (unshifted QR with Givens) for random matrix:\", eigs)  # Print eigenvalues for Givens\n",
        "print(\"Iterations (Givens):\", iter_count)  # Print number of iterations for Givens\n",
        "\n",
        "# Householder\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_random, method='householder')  # Householder\n",
        "print(\"Eigenvalues (unshifted QR with Householder) for random matrix:\", eigs)  # Print eigenvalues for Householder\n",
        "print(\"Iterations (Householder):\", iter_count)  # Print number of iterations for Householder\n",
        "\n",
        "# numpy\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_random, method='numpy')  # Numpy\n",
        "print(\"Eigenvalues (unshifted QR with numpy) for random matrix:\", eigs)  # Print eigenvalues for numpy\n",
        "print(\"Iterations (numpy):\", iter_count)  # Print number of iterations for numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJp8bok6iYBH",
        "outputId": "fca1c3db-9afe-4b2d-99a4-a67e7f9630ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues (unshifted QR with Givens) for random matrix: [ 2.50849166  0.66864594 -0.41153689  0.30520262 -0.28553389]\n",
            "Iterations (Givens): 410\n",
            "Eigenvalues (unshifted QR with Householder) for random matrix: [ 2.50849166  0.66864594 -0.41153689  0.30520262 -0.28553389]\n",
            "Iterations (Householder): 410\n",
            "Eigenvalues (unshifted QR with numpy) for random matrix: [ 2.50849166  0.66864594 -0.41153689  0.30520262 -0.28553389]\n",
            "Iterations (numpy): 410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A_random = np.random.rand(5, 5)\n",
        "A_random = (A_random + A_random.T) / 2  # Symmetrize\n",
        "\n",
        "# Givens\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_random, method='givens')  # Givens\n",
        "print(\"Eigenvalues (unshifted QR with Givens) for random matrix:\", eigs)  # Print eigenvalues for Givens\n",
        "print(\"Iterations (Givens):\", iter_count)  # Print number of iterations for Givens\n",
        "\n",
        "# Householder\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_random, method='householder')  # Householder\n",
        "print(\"Eigenvalues (unshifted QR with Householder) for random matrix:\", eigs)  # Print eigenvalues for Householder\n",
        "print(\"Iterations (Householder):\", iter_count)  # Print number of iterations for Householder\n",
        "\n",
        "# numpy\n",
        "eigs, A_final, iter_count, off_hist = unshifted_qr_eig(A_random, method='numpy')  # Numpy\n",
        "print(\"Eigenvalues (unshifted QR with numpy) for random matrix:\", eigs)  # Print eigenvalues for numpy\n",
        "print(\"Iterations (numpy):\", iter_count)  # Print number of iterations for numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxRfS99NkfYy",
        "outputId": "feebb053-5acd-4f06-cf2e-4ce5ac2477f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues (unshifted QR with Givens) for random matrix: [ 2.91128113 -0.54922574  0.25340445 -0.05082824 -0.00566829]\n",
            "Iterations (Givens): 41\n",
            "Eigenvalues (unshifted QR with Householder) for random matrix: [ 2.91128113 -0.54922574  0.25340445 -0.05082824 -0.00566829]\n",
            "Iterations (Householder): 41\n",
            "Eigenvalues (unshifted QR with numpy) for random matrix: [ 2.91128113 -0.54922574  0.25340445 -0.05082824 -0.00566829]\n",
            "Iterations (numpy): 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK 5:**\n",
        "First discuss execution times, iteration count has been already shown. Then, numerical stability and accuracy. Next we discuss the 3 methods in a summary and finally a conclusion about teh task."
      ],
      "metadata": {
        "id": "ZgsGXtWUqCPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Measure execution times for comparing efficiency:\n",
        "import time\n",
        "sizes = [2, 10, 50, 100, 200, 500, 1000]\n",
        "times_givens = []\n",
        "times_householder = []\n",
        "times_numpy = []\n",
        "\n",
        "for n in sizes:\n",
        "    A = np.random.rand(n, n)\n",
        "\n",
        "    # Givens\n",
        "    start = time.perf_counter()\n",
        "    Qg, Rg = qr_givens(A)\n",
        "    end = time.perf_counter()\n",
        "    times_givens.append(end - start)\n",
        "\n",
        "    # Householder\n",
        "    start = time.perf_counter()\n",
        "    Qh, Rh = qr_householder(A)\n",
        "    end = time.perf_counter()\n",
        "    times_householder.append(end - start)\n",
        "\n",
        "    # NumPy\n",
        "    start = time.perf_counter()\n",
        "    Qn, Rn = np.linalg.qr(A)\n",
        "    end = time.perf_counter()\n",
        "    times_numpy.append(end - start)\n",
        "\n",
        "print(times_givens)\n",
        "print(times_householder)\n",
        "print(times_numpy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5LXHiu_kibt",
        "outputId": "169b4101-24dc-499b-f755-011aac832774"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0003421620003791759, 0.00019496699951560004, 0.0004288419995646109, 0.004212046000247938, 0.004663800000344054, 0.038334011000188184, 0.1964720510004554]\n",
            "[5.148000036570011e-05, 8.330000036949059e-05, 0.0005647980005960562, 0.0008844829999361536, 0.0038490710003316053, 0.03290138400006981, 0.17570847099977982]\n",
            "[7.470199943782063e-05, 7.00290001987014e-05, 0.00024582900005043484, 0.0008302589994855225, 0.003715370999998413, 0.030003531000147632, 0.16678844099988055]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5  # or any size you want to test\n",
        "A = np.random.rand(n, n)\n",
        "\n",
        "# Givens\n",
        "Q_g, R_g = qr_givens(A)\n",
        "err_fact_g = np.linalg.norm(Q_g @ R_g - A)\n",
        "err_orth_g = np.linalg.norm(Q_g.T @ Q_g - np.eye(n))\n",
        "print(\"Givens:\")\n",
        "print(\"Reconstruction error:\", err_fact_g)\n",
        "print(\"Orthogonality error:\", err_orth_g)\n",
        "print()\n",
        "\n",
        "# Householder\n",
        "Q_h, R_h = qr_householder(A)\n",
        "err_fact_h = np.linalg.norm(Q_h @ R_h - A)\n",
        "err_orth_h = np.linalg.norm(Q_h.T @ Q_h - np.eye(n))\n",
        "print(\"Householder:\")\n",
        "print(\"Reconstruction error:\", err_fact_h)\n",
        "print(\"Orthogonality error:\", err_orth_h)\n",
        "print()\n",
        "\n",
        "# NumPy\n",
        "Q_np, R_np = np.linalg.qr(A)\n",
        "err_fact_np = np.linalg.norm(Q_np @ R_np - A)\n",
        "err_orth_np = np.linalg.norm(Q_np.T @ Q_np - np.eye(n))\n",
        "print(\"numpy's QR:\")\n",
        "print(\"Reconstruction error:\", err_fact_np)\n",
        "print(\"Orthogonality error:\", err_orth_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vxge_X3rDXP",
        "outputId": "46bcbeae-63d6-4135-8bea-e512b8162747"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Givens:\n",
            "Reconstruction error: 1.091966747121334e-15\n",
            "Orthogonality error: 1.190255306366136e-15\n",
            "\n",
            "Householder:\n",
            "Reconstruction error: 1.091966747121334e-15\n",
            "Orthogonality error: 1.190255306366136e-15\n",
            "\n",
            "numpy's QR:\n",
            "Reconstruction error: 1.091966747121334e-15\n",
            "Orthogonality error: 1.190255306366136e-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " From these measures we can see that overall Givens is significantly slower. Then the other 2 methods are pretty similar in terms of running time but as N starts getting bigger the difference becomes more evident (around 10% for large matrix size). So if our goal was to have the fastest performance we should use numpy and discard Givens."
      ],
      "metadata": {
        "id": "0LzHzf7bp_rI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that all methods yield errors in the order of exponent 15 or 16 which falls in machine precision so all 3 methods are reproducing the original matrix close to perfection so in terms of accuracy they perform equally well.  \n",
        "\n",
        "I believe that all these analysis and coding is complete enough so I will not be showing more measures. Conclude form my code and analysis plus reading and \"resources\" that:\n",
        "\n",
        "1. Householder is the method of choice for dense factorizations as it zeroes out an entire column in a single transformation; it is overall stable and easy to implement.\n",
        "\n",
        "2. Givens mehod is the choice when we do not need to zero out as much as in HH but it is enough with small number of elements; need to incrementally update a QR factorization here adding/removing a row/column can be done with feew Givens rotations not needing factorizing from zero. Also considerably stable.\n",
        "\n",
        "3. Numpy is the most optimal and fast one; also when one doe snot want to code more than small number of lines it is the best. Time put into coding vs result has the best ratio by far.\n",
        "\n",
        "4. In terms of numerical stability teh results are great as the errors are small, good stability and they match to many decimals the original matrices.\n",
        "\n",
        "5. All 3 methods return pretty similar results in terms of iteration counts, stability, accuracy, numerical stability..."
      ],
      "metadata": {
        "id": "XAf0REzNrbde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **CONCLUSION:**\n",
        " I have enjoyed this task very much as it seemed intuitive to follow, exciting to do and some of my hypothesis were accurate and some other were far from reality so had both the confirmation of my undrestanding and the learning from being mistaken. Also I got the chance of coding some parts with Blackbox AI which has been a great tool for fast coding. Plus reviewing notes from ALgebra and Linear Geometry for matrices when needed. I like when multiple areas of knowledge converge as here with Algebra part, AI part, coding(Python) part and of course the course itself: Numerical Methods.\n",
        "\n",
        " Task 4 was more of a nightmare for me :). Also the code was significantly slower in comparsion to this one, here we have some runs of hundreds of iterations and they are done in a second or so, no wait at all, the other needed some time\n",
        "\n",
        "Also I got the chance of switching form Visual Studio Code and Jupyter notebook to Google Collab that I had never used before and that can be easily exported to multiple formats or even link it with Github plus interface of coding/writing text has been nice for me."
      ],
      "metadata": {
        "id": "Fc5ZbJNJcmYa"
      }
    }
  ]
}